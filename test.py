#!/usr/bin/env python3
import os
import io
import wave
import time

import sounddevice as sd
import soundfile as sf
import speech_recognition as sr
import openai
import simpleaudio as sa

from dotenv import load_dotenv
from PIL import Image
import sys

# â”€â”€â”€ Display GC9A01 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
sys.path.append(os.path.join(os.path.dirname(__file__), 'library'))
from GC9A01 import GC9A01
display = GC9A01(
    port=0, cs=0, dc=25, backlight=18, rst=24,
    width=240, height=240, rotation=0, spi_speed_hz=40000000
)

def mostrar_imagem(nome):
    img = Image.open(nome).convert("RGB").resize((240,240))
    display.display(img)

# â”€â”€â”€ ConfiguraÃ§Ãµes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()

RECORD_SECONDS = 4
RECORD_FILE   = "captura.wav"

# â”€â”€â”€ InicializaÃ§Ã£o Ãºnica da tela â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
mostrar_imagem("robot.png")

# â”€â”€â”€ FunÃ§Ãµes de Ã¡udio â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def capturar_audio():
    print("ğŸ™ï¸ Gravando...")
    fs = 44100
    data = sd.rec(int(RECORD_SECONDS * fs), samplerate=fs,
                  channels=1, dtype="float32", device="default")
    sd.wait()
    data16 = (data * 32767).astype("int16")
    sf.write(RECORD_FILE, data16, fs, subtype="PCM_16")
    print("âœ… Ãudio salvo em", RECORD_FILE)

def transcrever():
    r = sr.Recognizer()
    with sr.AudioFile(RECORD_FILE) as src:
        audio = r.record(src)
    try:
        texto = r.recognize_google(audio, language="pt-BR")
        print("ğŸ—£ï¸ VocÃª disse:", texto)
        return texto
    except sr.UnknownValueError:
        print("â“ NÃ£o entendi.")
        return ""
    except sr.RequestError as e:
        print("âŒ Erro no serviÃ§o:", e)
        return ""

def chamar_chatgpt(prompt: str) -> str:
    resp = openai.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role":"system", "content":"VocÃª Ã© um assistente Ãºtil."},
            {"role":"user",   "content":prompt}
        ]
    )
    texto = resp.choices[0].message.content.strip()
    print("ğŸ¤– GPT diz:", texto)
    return texto

def texto_para_fala_wav(texto: str) -> bytes:
    out = openai.audio.speech.create(
        model="tts-1",
        voice="nova",
        input=texto,
        response_format="wav"
    )
    return out.content

def tocar_wav_bytes(bytes_wav: bytes):
    bio = io.BytesIO(bytes_wav)
    with wave.open(bio, "rb") as wf:
        wave_obj = sa.WaveObject(
            wf.readframes(wf.getnframes()),
            num_channels=wf.getnchannels(),
            bytes_per_sample=wf.getsampwidth(),
            sample_rate=wf.getframerate()
        )
    print("â–¶ï¸ Tocando respostaâ€¦")
    play = wave_obj.play()
    play.wait_done()
    print("âœ… Pronto.\n")

# â”€â”€â”€ Loop principal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("ğŸŸ¢ Assistente iniciado. Ctrl+C para sair.\n")
try:
    while True:
        capturar_audio()
        texto = transcrever()
        if not texto:
            continue

        resposta = chamar_chatgpt(texto)
        wav_bytes = texto_para_fala_wav(resposta)
        tocar_wav_bytes(wav_bytes)

        time.sleep(0.5)

except KeyboardInterrupt:
    print("\nğŸ”´ Encerrando assistente.")
    try:
        os.remove(RECORD_FILE)
    except FileNotFoundError:
        pass